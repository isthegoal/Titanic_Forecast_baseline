{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](1.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn  #这是一个可视化的展示库\n",
    "import random\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import sklearn.preprocessing as preprocessing\n",
    "from numpy import array\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#直接使用pandas对数据进行直观展示观看\n",
    "data=pd.read_csv('G:\\Machine-learning\\\\tensorflow-train-project(jupyter)\\kaggele-project6-tairanprediction\\dataset\\\\train.csv')\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 前置函数部分\n",
    "这里会先准备好补全信息函数(对缺失值的考虑十分重要)，属性值转换函数，数据归一化函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "#年龄信息补全函数：  这里 使用的方式是RandomForesetClassifier来填补\n",
    "def set_missing_ages(data):\n",
    "    age_df=data[['Age','Fare','Parch','SibSp','Pclass']]  #抽取一部分特征作为年龄相关特征时使用  这里使用五个特征[年龄、船票价格、父母子女数、经济状况]\n",
    "    #print('age_df:',age_df)\n",
    "    known_age=age_df[age_df.Age.notnull()].as_matrix()#   这是一种抽离，把知道年龄的数据抽取出来作为一个 矩阵，这个矩阵有包括上面的5个特征值\n",
    "    #print('known_age:',known_age)\n",
    "    unknown_age=age_df[age_df.Age.isnull()].as_matrix()  \n",
    "    \n",
    "    #接下来使用的事RandomForestClassifier算法来补全年龄特征，这里补全特征的思路是  使用除年龄外的其他特征来作为补全年龄的依据\n",
    "    y=known_age[:,0]\n",
    "    x=known_age[:,1:]\n",
    "    #创建补全算法，并进行数据喂养  随机森林中参数意义为：n_estimators 子模型个数  random_state指定随机器对象 参数可参考https://www.cnblogs.com/amberdata/p/7203632.html  \n",
    "    rfr=RandomForestRegressor(random_state=0,n_estimators=2000,n_jobs=-1)\n",
    "    rfr.fit(x,y)\n",
    "    #使用训练好的随机森林进行预测\n",
    "    predictedAges=rfr.predict(unknown_age[:,1::])#对不知道年龄的矩阵，使用其特征进行年龄的预测\n",
    "    data.loc[(data.Age.isnull()),'Age']=predictedAges#这是针对DateFrame的定位并填充残缺值的方式\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将属性转换为数值的函数\n",
    "def attribute_to_number(data):\n",
    "    #前三行会对属性进行独热编码\n",
    "    dummies_Pclass=pd.get_dummies(data['Pclass'],prefix='Pclass')#get_dummies会对属性进行独热编码\n",
    "    dummies_Embarked=pd.get_dummies(data['Embarked'],prefix='Embarked')\n",
    "    dummies_Sex=pd.get_dummies(data['Sex'],prefix='Sex')\n",
    "    #这里会将独热编码结果放到  组合结果的后面\n",
    "    data=pd.concat([data,dummies_Pclass,dummies_Embarked,dummies_Sex],axis=1) #concat不管列名,直接加到一起,可以加到后面、也可以加到右边,axis=0为加到后面,axis=1为加到右边\n",
    "    #针对这个类型，将前面没用的非数值属性去掉(使用后面新加入的 转化好的属性即可)\n",
    "    data.drop(['Pclass','Sex','Embarked'],axis=1,inplace=True)\n",
    "    return data\n",
    "#对属性值进行归一化操作\n",
    "def Scales(data):\n",
    "    scaler=preprocessing.StandardScaler()#StandardScaler用于数据标准化，计算训练集的平均值和标准差,以便测试数据集使用相同的变换\n",
    "    #对年龄进行归一化处理\n",
    "    age_scale_param=scaler.fit(data['Age'].reshape(-1,1))#这样转换，使其具有0均值，单位方差\n",
    "    data['Age_scaled']=scaler.fit_transform(data['Age'].reshape(-1,1),age_scale_param)#fit_transform可以进行最大最小的标准化\n",
    "    #对工资进行归一化处理\n",
    "    Fare_scale_param=scaler.fit(data['Fare'].reshape(-1,1))\n",
    "    data['Fare_scaled']=scaler.fit_transform(data['Fare'].reshape(-1,1),Fare_scale_param)\n",
    "    #对兄弟配偶数进行归一化处理\n",
    "    SibSp_scale_param=scaler.fit(data['SibSp'].reshape(-1,1))\n",
    "    data['SibSp_scaled']=scaler.fit_transform(data['SibSp'].reshape(-1,1),SibSp_scale_param)\n",
    "    #对父母子女数进行归一化处理\n",
    "    Parch_scale_param=scaler.fit(data['Parch'].reshape(-1,1))\n",
    "    data['Parch_scaled']=scaler.fit_transform(data['Parch'].reshape(-1,1),SibSp_scale_param)\n",
    "    #使用归一化后的数据，将之前的数据删去\n",
    "    data.drop(['Parch','SibSp','Fare','Age'],axis=1,inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第一部分\n",
    "读取数据集之后，现在我们进行数据的预处理，预处理包括提取主要特征（这里经过我们思考，感觉年龄和性别以及座位等级也许是比较中的特征信息，因此我们会将多余的信息删去）、补全数据、数据的归一化这些思路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataPreProcess(in_data,submat_flg):#数据预处理    submat_flg为1表示是针对测试数据的处理\n",
    "    #核心的几个预处理操作，有些函数需要自己手动去写\n",
    "    in_data.drop(['PassengerId','Name','Ticket','Cabin'],axis=1,inplace=True) #删去无关特征\n",
    "    data_ages_fitted=set_missing_ages(in_data)#补足年龄信息\n",
    "    data=attribute_to_number(data_ages_fitted)#类目属性转为数值型\n",
    "    data_scaled=Scales(data)#将转化为数值型的特征数据进行归一化\n",
    "    \n",
    "    #对特征数据和标签数据的划分   进行划分后作为新的数据返回\n",
    "    data_copy=data_scaled.copy(deep=True)  #将数据集进行完全的备份   深拷贝\n",
    "    data_copy.drop(['Pclass_1','Pclass_2','Pclass_3','Embarked_C','Embarked_Q','Embarked_S','Sex_female','Sex_male','Age_scaled','Fare_scaled','SibSp_scaled','Parch_scaled'],axis=1,inplace=True)\n",
    "    data_y=np.array(data_copy)#这里是删去了很多东西(进行一种选择性的删除，还有axis这个自己不太掌握)   剩下的作为y的标签\n",
    "    if submat_flg==0:\n",
    "        data_scaled.drop(['Survived'],axis=1,inplace=True)\n",
    "        data_X=np.array(data_scaled)#特征组合x，这是要进行网络输入所用的所有特征值\n",
    "        return data_X,data_y\n",
    "    if(submat_flg==1):\n",
    "        data_X=np.array(data_scaled)#特征组合x，这是要进行网络输入所用的所有特征值\n",
    "        return data_X,data_y\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第二部分\n",
    "创建计算图，使用逻辑回归算法根据预处理过的数据计算模型参数（纯套路，构建图，填充数据集）\n",
    "我们打算使用逻辑回归法，要用到的式子为 $y=w0x0+w1x1+w2x2+b$  这样的方式求出其中的w和b，这是要计算出的模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LR(data_X,data_y):\n",
    "    X_train,X_test,y_train,y_test=train_test_split(data_X,data_y,test_size=0.1,random_state=0)#按比例系数 划分训练集和测试集\n",
    "    #接下来的操作应该是将标签值确定的转化为1或者0标签\n",
    "    y_train=tf.concat([1-y_train,y_train],1)\n",
    "    y_test=tf.concat([1-y_test,y_test],1)\n",
    "\n",
    "    #设定参数和变量\n",
    "    learning_rate=0.0005\n",
    "    training_epochs=25\n",
    "    batch_size=10\n",
    "    display_step=10\n",
    "\n",
    "    #获取喂养特征的样例数量和  使用的特征数量\n",
    "    n_samples=X_train.shape[0]\n",
    "    n_feature=X_train.shape[1]\n",
    "    n_class=2#目标是进行二分类\n",
    "    #设定占位符，模型变量和模型\n",
    "    x=tf.placeholder(tf.float32,[None,n_feature])\n",
    "    y=tf.placeholder(tf.float32,[None,n_class])\n",
    "    W=tf.Variable(tf.zeros([n_feature,n_class]),name='weight')\n",
    "    b=tf.Variable(tf.zeros([n_class]),name='bias')\n",
    "    #创建计算模型\n",
    "    pred=tf.matmul(x,W)+b    \n",
    "    #计算准确率和损失函数\n",
    "    correct_prediction=tf.equal(tf.arg_max(pred,1),tf.arg_max(y,1))\n",
    "    accurary=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))#reduce_mean是针对张量求平均值的一种方式，而reduce_sum是针对的一种求和\n",
    "    cost=tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(logits=pred,labels=y))\n",
    "    optimizer=tf.train.MomentumOptimizer(learning_rate,0.9).minimize(cost)\n",
    "    init=tf.initialize_all_variables()\n",
    "    \n",
    "    #开始创建计算图，并启动训练过程,在训练过程中观察准确率的变化\n",
    "    with tf.Session() as sess:   \n",
    "        sess.run(init)\n",
    "        #进行50次训练批次的训练，每批次使用50个数据进行训练\n",
    "        for epoch in range(training_epochs):\n",
    "            avg_cost=0\n",
    "            total_batch=int(n_samples/batch_size)   #在每个训练批次里面  我们都会使用所有的数据进行训练，所以这里会有个除式计算\n",
    "            for i in range(total_batch):\n",
    "                _,c=sess.run([optimizer,cost],feed_dict={x:X_train[i*batch_size:(i+1)*batch_size],y:y_train[i*batch_size:(i+1)*batch_size,:].eval()})\n",
    "                avg_cost=c/total_batch#单批次下的损失值\n",
    "            plt.plot(epoch+1,avg_cost,'co')#把损失值变化 用plt图标来展示出来\n",
    "        \n",
    "            if(epoch+1)%display_step==0:#达到一定批次之后进行准确的输出展示\n",
    "                print('Epoch:',(epoch+1),',cost=',avg_cost)\n",
    "               # print('the Weight: ',sess.run(W),'  ,the bias:',sess.run(b))\n",
    "        X_test=sess.run(tf.convert_to_tensor(X_test))\n",
    "        y_test=sess.run(tf.convert_to_tensor(y_test))\n",
    "        print('Testing Accuracy:',sess.run(accurary,feed_dict={x:X_test,y:y_test}))#这个地方如果这样用，往feed_dict中传的是张量，这是tf的理解难点\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('cost')\n",
    "        plt.show()\n",
    "        W=sess.run(W)\n",
    "        b=sess.run(b)\n",
    "    return W,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\envs\\python35\\lib\\site-packages\\ipykernel_launcher.py:16: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  app.launch_new_instance()\n",
      "D:\\ProgramData\\Anaconda3\\envs\\python35\\lib\\site-packages\\ipykernel_launcher.py:17: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "D:\\ProgramData\\Anaconda3\\envs\\python35\\lib\\site-packages\\ipykernel_launcher.py:19: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "D:\\ProgramData\\Anaconda3\\envs\\python35\\lib\\site-packages\\ipykernel_launcher.py:20: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "D:\\ProgramData\\Anaconda3\\envs\\python35\\lib\\site-packages\\ipykernel_launcher.py:22: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "D:\\ProgramData\\Anaconda3\\envs\\python35\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "D:\\ProgramData\\Anaconda3\\envs\\python35\\lib\\site-packages\\ipykernel_launcher.py:23: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "D:\\ProgramData\\Anaconda3\\envs\\python35\\lib\\site-packages\\ipykernel_launcher.py:25: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "D:\\ProgramData\\Anaconda3\\envs\\python35\\lib\\site-packages\\ipykernel_launcher.py:26: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "D:\\ProgramData\\Anaconda3\\envs\\python35\\lib\\site-packages\\ipykernel_launcher.py:16: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  app.launch_new_instance()\n",
      "D:\\ProgramData\\Anaconda3\\envs\\python35\\lib\\site-packages\\ipykernel_launcher.py:17: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "D:\\ProgramData\\Anaconda3\\envs\\python35\\lib\\site-packages\\ipykernel_launcher.py:19: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "D:\\ProgramData\\Anaconda3\\envs\\python35\\lib\\site-packages\\ipykernel_launcher.py:20: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "D:\\ProgramData\\Anaconda3\\envs\\python35\\lib\\site-packages\\ipykernel_launcher.py:22: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "D:\\ProgramData\\Anaconda3\\envs\\python35\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "D:\\ProgramData\\Anaconda3\\envs\\python35\\lib\\site-packages\\ipykernel_launcher.py:23: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "D:\\ProgramData\\Anaconda3\\envs\\python35\\lib\\site-packages\\ipykernel_launcher.py:25: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "D:\\ProgramData\\Anaconda3\\envs\\python35\\lib\\site-packages\\ipykernel_launcher.py:26: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 ,cost= 0.0994856476784\n",
      "Epoch: 20 ,cost= 0.0937574744225\n",
      "Testing Accuracy: 0.811111\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the W: Tensor(\"Placeholder_283:0\", shape=(?, 2), dtype=float32) ,it type is <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "the b: [ 0.03232621 -0.03232621] ,it type is <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "#调用函数来启动计算过程  \n",
    "if __name__==\"__main__\":\n",
    "    data=pd.read_csv('G:\\Machine-learning\\\\tensorflow-train-project(jupyter)\\kaggele-project6-tairanprediction\\dataset\\\\train.csv')\n",
    "    submat_test_data=pd.read_csv('G:\\Machine-learning\\\\tensorflow-train-project(jupyter)\\kaggele-project6-tairanprediction\\dataset\\\\test.csv')\n",
    "    submat_test_data_PassengerId=submat_test_data['PassengerId']\n",
    "    data_x,data_y=DataPreProcess(data,0)\n",
    "    submat_test_data_x,submat_test_data_y=DataPreProcess(submat_test_data,1)\n",
    "    Weight,bias=LR(data_x,data_y)\n",
    "    print('the W:',W,',it type is',type(W))\n",
    "    print('the b:',b,',it type is',type(b))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submat shape: (418, 12)\n",
      "Weight shape: (12, 2)\n",
      "bias shape: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "#使用计算得到的W和b参数重新启动计算过程     在会话中进行获救结果的预测，并保持在一个csv文件中\n",
    "#创建计算图点\n",
    "n_features=submat_test_data_x.shape[1]\n",
    "n_Weight=Weight.shape[1]\n",
    "n_bias=bias.shape\n",
    "X=tf.placeholder(tf.float32,[None,n_features])\n",
    "W=tf.placeholder(tf.float32,[None,n_Weight])\n",
    "B=tf.placeholder(tf.float32,n_bias)#因为是一维的直接放置就行了\n",
    "yHat=tf.add(tf.matmul(X,W),B)\n",
    "last_result=tf.arg_max(yHat,1)   #构建计算图，直接放置即可    自己想出来的方法\n",
    "with tf.Session() as sess2:\n",
    "    tf.global_variables_initializer().run()\n",
    "    submat_test_data_x=sess2.run(tf.convert_to_tensor(submat_test_data_x))\n",
    "    Weight=sess2.run(tf.convert_to_tensor(Weight))\n",
    "    bias=sess2.run(tf.convert_to_tensor(bias))\n",
    "    print('submat shape:',submat_test_data_x.shape)\n",
    "    print('Weight shape:',Weight.shape)\n",
    "    print('bias shape:',type(bias))\n",
    "    predictions_to=sess2.run([last_result],feed_dict={X:submat_test_data_x,W:Weight,B:bias})#np.argmax用于得到数组最大值的索引  整体获得预测结果\n",
    "    #predictions_to=sess2.run(tf.arg_max(tf.convert_to_tensor(predictions),1))\n",
    "    #print('predictions:',predictions_to[0].shape)\n",
    "submission=pd.DataFrame({'PassengerId':submat_test_data_PassengerId,'Survived':predictions_to[0]})#构造一个表，用于放置预测结果    predictions_to[0]语句相当于把这取出来了\n",
    "submission.to_csv('submit.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
